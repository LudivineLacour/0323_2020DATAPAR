{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storytelling Data Visualization Lab\n",
    "\n",
    "In this lab you'll use a dataset called `housing_prices.csv` which contains the sales data of houses. The dataset and descriptions of the columns are available from [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data). For your convenience, you can review the descriptions of the data columns from [here](data-description.txt).\n",
    "\n",
    "Pretend you are a data analyst at an investment company where the board decided to make investments in real estates. Your boss asked you to analyze this housing sales dataset and present to the investment managers on **what features of houses are strong indicators of the final sale price**. You need to present your findings in intuitive ways so that the investment managers understand where your conclusions come from.\n",
    "\n",
    "#### You will use the appropriate data visualization graphs to tell your stories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1 - Understanding the Dataset\n",
    "\n",
    "After receiving the data and clarifying your objectives with your boss, you will first try to understand the dataset. This allows you to decide how you will start your research in the next step.\n",
    "\n",
    "#### First, import the basic libraries and the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('housing_prices.csv')\n",
    "pd.set_option('max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As a routine before analyzing a dataset, print the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You find the dataset has 81 columns which are a lot. \n",
    "\n",
    "#### Since the column `Id` is meaningless in our data visualization work, let's drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Id',inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You care about missing values. If a column has too many missing values, it is not reliable to use it to predict sales price.\n",
    "\n",
    "#### In the cell below, calculate the percentage of missing values for each column. \n",
    "\n",
    "Make a table containing the column name and the percentage of missing values. Print the columns where more than 20% of values are missing. An example of your output looks like:\n",
    "\n",
    "![Missing Values](missing-values.png)\n",
    "\n",
    "[This reference](https://stackoverflow.com/questions/51070985/find-out-the-percentage-of-missing-values-in-each-column-in-the-given-dataset) can help you make the missing values table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 100 * df.isna().sum()/df.shape[0]\n",
    "missing_val = pd.DataFrame(percent,columns=['percent_missing']).sort_values(by='percent_missing',ascending=False)\n",
    "missing_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the columns you find that have more than 20% missing values.\n",
    "\n",
    "After dropping, check the shape of your dataframes. You should have 75 columns now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(missing_val[missing_val['percent_missing']>20].index,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you're asked to analyze sale prices, first let's see if the sale prices (column `SalePrice`) has a normal distribution. This is important because normally distributed data can be better represented with mathematical models.\n",
    "\n",
    "#### In the cell below, use the propriate graph to visualize the shape of distribution of the sale prices. Then explain what you find from the graph about data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df.SalePrice);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SalePrice.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The distribution of SalePrice is slightly skewed to the left.\n",
    "It is confirmed by the mean and the mediane that are not equals.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge 1 - Adjust Data Distribution\n",
    "\n",
    "If you used the correct method in the previous step, you should have found the data distribution is skewed to the left. In order to improve your data visualization in the next steps, you can opt to adjust the `SalePrice` column by applying a mathematical function to the values. The goal is to produce a bell-shape normal distribution after applying the mathematical function to the sale price.\n",
    "\n",
    "*This technique is optional in data visualization but you'll find it useful in your future machine learning analysis.*\n",
    "\n",
    "#### In the cell below, adjust the `SalePrice` column so that the data are normally distributed.\n",
    "\n",
    "Try applying various mathematical functions such as square root, power, and log to the `SalePrice` column. Visualize the distribution of the adjusted data until you find a function that makes the data normally distributed. **Create a new column called `SalePriceAdjusted` to store the adjusted sale price.**\n",
    "\n",
    "[This reference](https://trainingdatascience.com/workshops/histograms-and-skewed-data/) shows you examples on how to adjust skewed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization to logarithmic \n",
    "\n",
    "df_exp = df.SalePrice.apply(np.log)\n",
    "sns.distplot(df_exp);\n",
    "\n",
    "df_exp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization to Square Root \n",
    "\n",
    "df_sqrt = df.SalePrice.apply(np.sqrt)\n",
    "sns.distplot(df_sqrt);\n",
    "\n",
    "df_sqrt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization to Power\n",
    "\n",
    "df_pow = df.SalePrice.apply(lambda x: x**2)\n",
    "sns.distplot(df_pow);\n",
    "\n",
    "df_pow.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize with logarithmic function because it seems to be the most normally distributed data.\n",
    "\n",
    "df['SalePriceAdjusted'] = df.SalePrice.apply(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2 - Exploring Data with Common Sense\n",
    "\n",
    "Now that we have a general understanding of the dataset, we start exploring the data with common sense by means of data visualization. Yes, in data analysis and even machine learning you are often required to use common sense. You use your common sense to make a scientific guess (i.e. hypothesis) then use data analytics methods to test your hypothesis.\n",
    "\n",
    "This dataset is about housing sales. According to common sense, housing prices depend on the following factors:\n",
    "\n",
    "* **Size of the house** (`GrLivArea`, `LotArea`, and `GarageArea`).\n",
    "\n",
    "* **Number of rooms** (`BedroomAbvGr`, `KitchenAbvGr`, `FullBath`, `HalfBath`, `BsmtFullBath`, `BsmtHalfBath`).\n",
    "\n",
    "* **How long the house has been built or remodeled** (`YearBuilt` and `YearRemodAdd`).\n",
    "\n",
    "* **Neighborhood of the house** (`Neighborhood`).\n",
    "\n",
    "#### In this challenge, use the appropriate graph type to visualize the relationships between `SalePrice` (or `SalePriceAdjusted`) and the fields above. \n",
    "\n",
    "Note that:\n",
    "\n",
    "* Transform certain columns in order to visualize the data properly based on common sense. For example:\n",
    "    * Visualizing how the number of half bathrooms affected the sale price probably does not make sense. You can create a new column to calculate the total number of bathrooms/rooms then visualize with the calculated number.\n",
    "    * `YearBuilt` and `YearRemodAdd` are year numbers not the age of the house. You can create two new columns for how long the house has been built or remodeled then visualize with the calculated columns.\n",
    "* Make comments to explain your thinking process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns to calculate how long the house has been built or remodeled\n",
    "\n",
    "df['years_since_built'] = 2020-df.YearBuilt\n",
    "df['years_since_remodeled'] = 2020-df.YearRemodAdd\n",
    "df.iloc[:,-5:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column to get the number of bathroom per rooms above grade\n",
    "df['HalfBath'] = df['HalfBath']/2\n",
    "df['total_bathrooms'] = df[['FullBath', 'HalfBath']].sum(axis=1)\n",
    "df['bath_per_rooms'] = df[['FullBath', 'HalfBath']].sum(axis=1) / df['TotRmsAbvGrd']\n",
    "df.iloc[:,-5:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new df filtered with the intesresting columns\n",
    "\n",
    "sub_df = df[['GrLivArea', 'LotArea', 'GarageArea','BedroomAbvGr', 'KitchenAbvGr','Neighborhood']+list(df.iloc[:,-5:])]\n",
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating scatter plots to compare Sales Prices Adjusted with interesting features\n",
    "fig, axes = plt.subplots(5,2, figsize=(10,17))\n",
    "\n",
    "for idx,col in enumerate(sub_df.drop(columns='SalePriceAdjusted')):\n",
    "    ax = axes[idx//2,idx%2]\n",
    "    sns.scatterplot(data=sub_df,x=col,y='SalePriceAdjusted',ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=> The Grade Living Area itself and the Garage Area seems to affect positively the price of houses,\n",
    "compared to the Lot Area itself. \n",
    "\n",
    "We may assume that a house with a large basement area wouldn't make the price of the house \n",
    "higher even if it increases the total area of living. \n",
    "\n",
    "=> We can see the Neighborhood affects the price a lot. \n",
    "\n",
    "=> Having 1 from to 4 bedrooms above the grade affects positively the price, \n",
    "with 4 bedrooms which seems to be the sweet spot for an house with immediate higher price at the begining.\n",
    "\n",
    "=> We may see a slight negative correlation between the years of building or remodeling and the price. \n",
    "That would mean the price may decrease as the years increase.\n",
    "\n",
    "=> We can see the price is positively affected by the number of bathrooms above grade but \n",
    "it should stay relative to number of rooms above the grade.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge 2 - Exploring Data with Correlation Heatmap\n",
    "\n",
    "Now you have explored data visualizations with certain fields based on common sense. In the dataset there are many other fields that you are not sure whether they are important factors for the sale price. What is the best way to explore those fields without investigating them individually?\n",
    "\n",
    "Making scatter matrix is not an option here because there are too many fields which makes it extremely time consuming to create scatter matrix. One option you have is to create a heatmap. Heatmaps are much less expensive to create than scatter matrixes. You can use heatmaps to visualize the pairwise correlations between each two variables.\n",
    "\n",
    "Here is a [reference](https://seaborn.pydata.org/examples/many_pairwise_correlations.html) you can use to learn how to creat the pairwise correlation heatmap. Your heatmap should look like below:\n",
    "\n",
    "![Corr Heatmap](heatmap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(17, 12))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your heatmap, you can easily identify the highly correlated (either positively or negatively) variables by looking for the grids with darker colors. \n",
    "\n",
    "#### In the cell below, summarize what variables are highly correlated to the sale price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Most correlated variables to Sale Price is first of all the Over Quality (Overall material and finish quality),\n",
    "which makes a lot of sense but it requires to know more about what kind of material and finish are qualitatives.\n",
    "\n",
    "Otherwise, the grade living area, the garage area, if there is garage for cars, \n",
    "the total bathrooms and the total rooms above grade affects the price. \n",
    "Then, the neighborhood is also one feature that impact a lot the price.\n",
    "\n",
    "Finally, we can see the age of the house (same for the age of remodeling) affect negatively the price. \n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3 - Present Your Stories\n",
    "\n",
    "Now based on your findings from the explorations, summarize and present your stories.\n",
    "\n",
    "#### Present the top 5 factors that affect the sale price.\n",
    "\n",
    "Use the following format to present each factor:\n",
    "\n",
    "1. A title line about the factor.\n",
    "\n",
    "1. No more than 3 sentences to describe the relationship between the factor and the sale price.\n",
    "\n",
    "1. Support your point with the appropriate graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Neighborhood\n",
    "\n",
    "The neighborhood is one the main feature that affect the price. \n",
    "Depending on it, the start price for an house can immediately jump. \n",
    "\n",
    "The most expensive houses are located in the NoRidge neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.scatterplot(data=df,x='Neighborhood',y='SalePriceAdjusted')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Sale Price by Neighborhood')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Overall Quality\n",
    "\n",
    "The material and finish quality of the house affect a lot the price of house. The price clearly increase as the quality increase. \n",
    "\n",
    "The main point here would be to get to know what material and finish affect most the quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.regplot(data=df,x='OverallQual',y='SalePriceAdjusted')\n",
    "plt.title('Correlation between Overall Quality and Sale Price',fontsize=14,pad=20)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Living Area\n",
    "\n",
    "The Grade Living Area itself and the Garage Area seems to affect positively the price of houses,\n",
    "compared to the Lot Area itself. \n",
    "\n",
    "Also, the price seems to increase as the more the garage can get cars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(17,4))\n",
    "\n",
    "sns.scatterplot(data=df,x='GrLivArea',y='SalePriceAdjusted', color='b', ax=axes[0])\n",
    "sns.scatterplot(data=df,x='GarageArea',y='SalePriceAdjusted', color='orange', ax=axes[1])\n",
    "#sns.scatterplot(data=df,x='LotArea',y='SalePriceAdjusted', color='g', ax=axes[2])\n",
    "fig.suptitle('Correlation between Area and Sale Price',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bathrooms but not too much\n",
    "\n",
    "The price seems to increase when there is more bathrooms above the grade in the house. \n",
    "\n",
    "But we can see that the number of bathroom should be relative to the number of rooms in the house.\n",
    "If there is too much bathrooms compared the the number of other rooms, the price won't be positively affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(14,4))\n",
    "\n",
    "sns.scatterplot(data=df,x='total_bathrooms',y='SalePriceAdjusted',ax=axes[0])\n",
    "sns.scatterplot(data=df,x='bath_per_rooms',y='SalePriceAdjusted',ax=axes[1])\n",
    "fig.suptitle('Correlation between Bathrooms and Sale Price',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time matters\n",
    "\n",
    "Becarful with how long the house has been built or remodeled. \n",
    "\n",
    "We can see that the price decrease slighly as the years of building or remodeling increase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(14,4))\n",
    "\n",
    "sns.regplot(data=df,x='years_since_built',y='SalePriceAdjusted',ax=axes[0])\n",
    "sns.regplot(data=df,x='years_since_remodeled',y='SalePriceAdjusted',ax=axes[1])\n",
    "fig.suptitle('Correlation between Time and Sale Price',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
